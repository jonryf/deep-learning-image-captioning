{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Decoder import Decoder\n",
    "from Encoder import Encoder\n",
    "from evaluate_captions import evaluate_captions\n",
    "from runner import Runner\n",
    "from settings import LSTM_HIDDEN_SIZE, EMBEDDED_SIZE\n",
    "from utils import load_datasets, get_device\n",
    "from glove import loadGlove\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 50\n",
    "\n",
    "glove = loadGlove()\n",
    "print(\"Loaded glove\")\n",
    "train_dataset, val_dataset, test_dataset = load_datasets()\n",
    "\n",
    "vocabulary_size = len(train_dataset.dataset.vocab.wordToIndex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_weights = np.zeros((vocabulary_size, embed_size))\n",
    "missed_words = 0\n",
    "found_words = 0\n",
    "\n",
    "for i, word in enumerate(train_dataset.dataset.vocab.wordToIndex.keys()):\n",
    "    try: \n",
    "        glove_weights[i] = glove[word]\n",
    "        found_words += 1\n",
    "    except KeyError:\n",
    "        glove_weights[i] = np.random.normal(scale=0.6, size=(embed_size, ))\n",
    "        missed_words += 1\n",
    "\n",
    "print(\"{} words not in glove\".format(missed_words))\n",
    "print(\"{} words found\".format(found_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computing_device = get_device()\n",
    "\n",
    "encoder = Encoder(embed_size).to(computing_device)\n",
    "decoder = Decoder(embed_size, LSTM_HIDDEN_SIZE, vocabulary_size).to(computing_device)\n",
    "\n",
    "(num_embed, embed_dim) = glove_weights.shape\n",
    "\n",
    "embed_layer = nn.Embedding(num_embed, embed_dim).to(computing_device)\n",
    "#glove_weights = torch.tensor(glove_weights).to(computing_device)\n",
    "\n",
    "embed_layer.load_state_dict({'weight': glove_weights})\n",
    "\n",
    "decoder.embedding = embed_layer\n",
    "\n",
    "runner = Runner(encoder, decoder, train_dataset, val_dataset, test_dataset)\n",
    "runner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
